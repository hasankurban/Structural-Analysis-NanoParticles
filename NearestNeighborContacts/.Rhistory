#Cluster mydata with k-means, k=2
#nstart: how many random sets should be chosen?
#nstart = 20 and k = 2 means that 20 times, randomly choose 2 initial points
#and initialize k-means algorithm with these initial points
#and return the result for the best initial points (SSE lowest)
km.out=kmeans(mydata,centers=2,nstart=20)
# Total within-cluster sum of squares
km.out$tot.withinss
#k=3: Run k-means for 3-clusters
km.out=kmeans(mydata,3,nstart=20)
#Total within-cluster sum of squares
km.out$tot.withinss
k_max <- 10
#Total within-cluster sum of squares
tsse <- sapply(1:k_max,
function(k){kmeans(mydata, k, nstart=30,iter.max = 12 )$tot.withinss})
plot(1:k_max, tsse,
type="b", pch = 20, frame = FALSE,
xlab="Number of clusters k",
ylab="Total within-clusters sum of squares")
x = (1,1)
x = [1,1]
x <- c(1,1)
y <- (2,2)
y = c(2,2)
cor(X,y)
cor(x,y)
?cor
var(x,y)
x <- c(1,1,1,1,1,1,1,1)
y <-  c(2,2,2,2,2,2,2,2)
cor(x,y)
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(1,2,2,3),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(-1,-2,-2,-3),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(-1,-2,2,3),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
A
A = matrix(c(0,-2,2,0),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
A = matrix(c(0,-2,-2,0),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
A
A = matrix(c(0,-2,-2,0),ncol=2)
A
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
A
A = matrix(c(2,4,4,6),ncol=2)
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(0,-2,-2,0),ncol=2)
A
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
A = matrix(c(-1,-2,2,3),ncol=2)
A
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(0,-2,-2,0),ncol=2)
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
# @Hasan Kurban: Toy PCA example, 2018
# B365 Intro to Data Analysis and Mining
##########################################################################################
#Example 1:
#A = matrix(c(2,4,4,6),ncol=2)
#Example 2:
#A = matrix(c(1,2,-3,-2,6,8),ncol=2)
#Example 3:
#A = matrix(c(1,1,3,5),ncol=2)
# 1. Center data
A = matrix(c(0,-2,-2,0),ncol=2)
A
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
A = matrix(c(-1,-2,2,3),ncol=2)
A
A.center <- scale(A, scale = FALSE)
A.center
# 2. Covariance matrix
A.center.cov <- cov(A.center)
A.center.cov
# 3. eigen value and eigen vectors
A.eigen <- eigen(A.center.cov)
A.eigen
#unlist A.eigen and store eigen vectors in a matrix
A.eigenVectors <- t(matrix(unlist(A.eigen[2]), ncol = 2, byrow = TRUE))
A.eigenVectors #
#4.  PCs: new data
PC <- A.center %*% A.eigenVectors
PC <- as.data.frame(PC)
names(PC) <- c("PC1", "PC2")
PC
107+700+128+300+200+70+60+100+50
107+700+128+300+200+70+60+100+50 +315
30+30+30+40+20+15+50
6500/85
76.47059 - 53.2
6224.5/85
train.X=cbind(Lag1,Lag2)[train,]
test.X=cbind(Lag1,Lag2)[!train,]
train.Direction=Direction[train]
set.seed(1)
library(ISLR)
names(Smarket)
# The Stock Market Data
install.packages(ISLR)
library(ISLR)
# The Stock Market Data
install.packages("ISLR")
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
cor(Smarket)
cor(Smarket[,-9])
attach(Smarket)
plot(Volume)
train.X=cbind(Lag1,Lag2)[train,]
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
train.X=cbind(Lag1,Lag2)[train,]
test.X=cbind(Lag1,Lag2)[!train,]
train.Direction=Direction[train]
set.seed(1)
?knn
knn.pred=knn(train.X,test.X,train.Direction,k=1)
library(class)
knn.pred=knn(train.X,test.X,train.Direction,k=1)
table(knn.pred,Direction.2005)
knn.pred
table(knn.pred,Direction.2005)
knn.pred=knn(train.X,test.X,train.Direction,k=3)
table(knn.pred,Direction.2005)
mean(knn.pred==Direction.2005)
table(knn.pred,Direction.2005)
48+87
54+63
# An Application to Caravan Insurance Data
require("caret")
dim(Caravan)
attach(Caravan)
View(Caravan)
summary(Purchase)
348/5822
standardized.X=scale(Caravan[,-86])
var(Caravan[,1])
var(Caravan[,2])
var(standardized.X[,1])
var(standardized.X[,2])
test=1:1000
train.X=standardized.X[-test,]
test.X=standardized.X[test,]
train.Y=Purchase[-test]
test.Y=Purchase[test]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Y,k=1)
knn.pred
table(knn.pred,test.Y)
dim(Smarket)
View(Smarket)
# Training Data and Test Data
train=(Year<2005)
View(Smarket)
train.X=cbind(Lag1,Lag2)[train,]
train.X
test.X=cbind(Lag1,Lag2)[!train,]
train.Direction=Direction[train]
set.seed(1)
library(class)
?CLASS
?class
# An Application to Caravan Insurance Data
require("caret")
dim(Caravan)
View(Cravan)
View(Caravan)
summary(Purchase)
View(Caravan)
install.packages("ISLR")
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
pairs(Smarket)
cor(Smarket)
cor(Smarket[,-9])
attach(Smarket)
plot(Volume)
install.packages("ISLR")
#An Introduction to Data Anaylsis and Mining, IUB, Spring 2018
#Instructor: Hasan Kurban
#1. Naive Bayes via "caret package"
install.packages("caret")
library("caret")
head(iris)
# In this part, we first train a naive bayes classifier over training data,
# and then use the model over test data
set.seed(1234)
# Creating training  and testing  data sets: Randomly picking 100 data points from Iris data set
# as training data and the rest of 50 data points will be used as test data.
rndSample <- sample(1:nrow(iris),100)
tr <- iris[rndSample, ]  # training data: 100 data points
ts <- iris[-rndSample, ] #  testing data: 50 data points
?train
# Training a Naive Bayes classifier
model = train(tr[,1:4],tr[,5],'nb',trControl=trainControl(method='cv',number=10))
# Using model to make prediction
predict(model$finalModel,ts[,1:4])
#confusion matrix
table(predict(model$finalModel,ts[,1:4])$class,ts[,5])
#2. Naive Bayes via "e1071 package"
#default distribution for continous variables is a normal distribution.
install.packages("e1071")
library(e1071)
#training
model2 <- naiveBayes(tr$Species ~ ., data = tr)
model2
# Using the model to make predictions
predict(model2,ts[,1:4])
#confusion matrix
table(predict(model2,ts[,1:4]),ts[,5])
install.packages("e1071")
View(iris)
rndSample <- sample(1:nrow(iris),100)
tr <- iris[rndSample, ]  # training data: 100 data points
ts <- iris[-rndSample, ] #  testing data: 50 data points
# Training a Naive Bayes classifier
model = train(tr[,1:4],tr[,5],'nb',trControl=trainControl(method='cv',number=10))
model
#training
model2 <- naiveBayes(tr$Species ~ ., data = tr)
model2
#training
model2 <- naiveBayes(tr$Species ~ ., data = tr)
model2
# Using the model to make predictions
predict(model2,ts[,1:4])
#confusion matrix
table(predict(model2,ts[,1:4]),ts[,5])
#confusion matrix
table(predict(model2,ts[,1:4]),ts[,5])
# Creating training  and testing  data sets: Randomly picking 100 data points from Iris data set
# as training data and the rest of 50 data points will be used as test data.
rndSample <- sample(1:nrow(iris),100)
tr <- iris[rndSample, ]  # training data: 100 data points
ts <- iris[-rndSample, ] #  testing data: 50 data points
#training
model2 <- naiveBayes(tr$Species ~ ., data = tr)
model2
# Using the model to make predictions
predict(model2,ts[,1:4])
#confusion matrix
table(predict(model2,ts[,1:4]),ts[,5])
# Training a Naive Bayes classifier
model = train(tr[,1:4],tr[,5],'nb',trControl=trainControl(method='cv',number=10))
# Using model to make prediction
predict(model$finalModel,ts[,1:4])
#confusion matrix
table(predict(model$finalModel,ts[,1:4])$class,ts[,5])
# Training a Naive Bayes classifier
model = train(tr[,1:4],tr[,5],'nb',trControl=trainControl(method='cv',number=10))
model
?train
?simplEM
?EM
??EM
5.3- 4.77
53/4.77
?DCEM
install.packages(dcem)
install.packages(c("BH", "bindr", "bindrcpp", "bit", "blob", "broom", "car", "caret", "chron", "classInt", "cluster", "curl", "CVST", "data.table", "DBI", "ddalpha", "digest", "dplyr", "e1071", "forcats", "foreign", "ggplot2", "glue", "gsubfn", "haven", "highr", "hms", "httpuv", "ipred", "iterators", "kernlab", "labelled", "lava", "lme4", "lubridate", "MASS", "Matrix", "mclust", "mgcv", "miniUI", "ModelMetrics", "munsell", "nlme", "pillar", "pkgconfig", "plogr", "prodlim", "psych", "purrr", "quantmod", "quantreg", "questionr", "Rcpp", "RcppEigen", "RcppRoll", "recipes", "rJava", "rlang", "robustbase", "rpart", "rpart.plot", "RSQLite", "scales", "shiny", "sourcetools", "stringi", "stringr", "survival", "tibble", "tidyr", "TTR", "utf8", "viridisLite", "XLConnect", "XLConnectJars", "xtable", "xts", "zoo"))
?DCEM
??DCEM
?DCEM
70 *6
49*4/10
56*6
65*6
55*4
70*6
39*4
75*6
74*6
39*4
48*4
70*6
65*6
68*6
2^20
2^20 %%119
2^24 %%119
2^6 %%119
5^6
15625 %% 23
setwd("~/Desktop/LASTCODE/data")
source("NearestNeighborContacts2.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
source("NearestNeighborContacts2.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
source("NearestNeighborContacts2.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
source("NearestNeighborContacts2.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
data
data
total.count.frame
data <- read.table("NNdata.txt", sep=",", header=TRUE)
data
has = data %>% mutate(data[,2:length(data)])
has = data %>% mutate(data)
data
has = data %>% mutate(data[,-1])
has = data %>% gather(variable, value, -n)
has
source("NearestNeighborContacts2.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
setwd("~/Desktop/LASTCODE/nearestNumberContacts")
source("NearestNeighborContacts2.R")
source("NearestNeighborContacts2.R")
source("NearestNeighborContacts.R")
nearest.neighbor.contacts("elements.txt","nFile.txt")
